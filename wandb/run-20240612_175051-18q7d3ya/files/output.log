batch_size: 28
train_steps: 2
context length: 250
num_tasks: 4
output_dir: ../outputs/GPT2/240612_175051.9ed302_unifA_unif_C
checkpoint_callback /Users/sultandaniels/Documents/Transformer_Kalman/outputs/GPT2/240612_175051.9ed302_unifA_unif_C/checkpoints
ckpt_path: ../outputs/GPT2/240612_175051.9ed302_unifA_unif_C/checkpoints/step=2.ckpt
Checkpoint file ../outputs/GPT2/240612_175051.9ed302_unifA_unif_C/checkpoints/step=2.ckpt does not exist.
Epoch 0:   0%|                                                                                                                                                                                             | 0/2 [00:00<?, ?it/s]
GPU available: True (mps), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/Users/sultandaniels/anaconda3/envs/mop/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.
/Users/sultandaniels/anaconda3/envs/mop/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:391: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  | Name      | Type      | Params
----------------------------------------
0 | _read_in  | Linear    | 768
1 | _backbone | GPT2Model | 9.1 M
2 | _read_out | Linear    | 645
----------------------------------------
9.1 M     Trainable params
0         Non-trainable params
9.1 M     Total params
36.304    Total estimated model params size (MB)
/Users/sultandaniels/anaconda3/envs/mop/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.

Epoch 0: 100%|█| 2/2 [00:07<00:00,  0.28it/s, v_num=d3ya, train_loss_mse_step=1.020, train_metric_mse_ts0_dim_0_step=0.527, train_metric_mse_ts0_dim_1_step=1.490, train_metric_mse_ts0_dim_2_step=0.106, train_metric_mse_ts0_di

Epoch 0: 100%|█| 2/2 [00:08<00:00,  0.23it/s, v_num=d3ya, train_loss_mse_step=1.020, train_metric_mse_ts0_dim_0_step=0.527, train_metric_mse_ts0_dim_1_step=1.490, train_metric_mse_ts0_dim_2_step=0.106, train_metric_mse_ts0_di
ckpt_path ../outputs/GPT2/240612_175051.9ed302_unifA_unif_C/checkpoints/step=2.ckpt
config path: ../outputs/GPT2/240612_175051.9ed302_unifA_unif_C/checkpoints/step=2.ckpt
Number of validation systems: 3
Number of traces: 7
parent_dir: ../outputs/GPT2/240612_175051.9ed302_unifA_unif_C/checkpoints
parent_parent_dir: ../outputs/GPT2/240612_175051.9ed302_unifA_unif_C
time elapsed: 0.025173298517862954 min
err_lss keys: odict_keys(['Kalman', 'MOP', 'Zero'])
analytical_kf.shape: (3,)
err_lss[Analytical_Kalman].shape: (3, 250)
IR length: 1
time elapsed: 0.030698482195536295 min
IR length: 2
time elapsed: 0.03480668862660726 min
IR length: 3
Traceback (most recent call last):
  File "/Users/sultandaniels/Documents/Transformer_Kalman/mop_modifications/streamlined_mop/src/data_train.py", line 104, in <module>
    create_plots(config, run_preds, run_deg_kf_test, excess, num_systems=config.num_val_tasks, shade=shade)
  File "/Users/sultandaniels/Documents/Transformer_Kalman/mop_modifications/streamlined_mop/src/create_plots_with_zero_pred.py", line 579, in create_plots
    save_preds(run_deg_kf_test, config) #save the predictions to a file
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sultandaniels/Documents/Transformer_Kalman/mop_modifications/streamlined_mop/src/create_plots_with_zero_pred.py", line 468, in save_preds
    raise ValueError("stop here")
ValueError: stop here
time elapsed: 0.035636651515960696 min
err_lss keys end odict_keys(['Zero', 'Analytical_Kalman', 'OLS', 'OLS_analytical', 'OLS_wentinn', 'OLS_ir_length1_orig', 'OLS_ir_length2_orig', 'OLS_ir_length3_orig'])
err_lss keys: odict_keys(['Zero', 'Analytical_Kalman', 'OLS', 'OLS_analytical', 'OLS_wentinn', 'OLS_ir_length1_orig', 'OLS_ir_length2_orig', 'OLS_ir_length3_orig'])