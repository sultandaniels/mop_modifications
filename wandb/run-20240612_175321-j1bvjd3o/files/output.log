batch_size: 28
train_steps: 2
context length: 250
num_tasks: 4
output_dir: ../outputs/GPT2/240612_175321.9ed302_unifA_unif_C
checkpoint_callback /Users/sultandaniels/Documents/Transformer_Kalman/outputs/GPT2/240612_175321.9ed302_unifA_unif_C/checkpoints
ckpt_path: ../outputs/GPT2/240612_175321.9ed302_unifA_unif_C/checkpoints/step=2.ckpt
Checkpoint file ../outputs/GPT2/240612_175321.9ed302_unifA_unif_C/checkpoints/step=2.ckpt does not exist.
Epoch 0:   0%|                                                                                                                                                                                             | 0/2 [00:00<?, ?it/s]
GPU available: True (mps), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/Users/sultandaniels/anaconda3/envs/mop/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.
/Users/sultandaniels/anaconda3/envs/mop/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:391: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  | Name      | Type      | Params
----------------------------------------
0 | _read_in  | Linear    | 768
1 | _backbone | GPT2Model | 9.1 M
2 | _read_out | Linear    | 645
----------------------------------------
9.1 M     Trainable params
0         Non-trainable params
9.1 M     Total params
36.304    Total estimated model params size (MB)
/Users/sultandaniels/anaconda3/envs/mop/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.

Epoch 0: 100%|█| 2/2 [00:06<00:00,  0.29it/s, v_num=jd3o, train_loss_mse_step=1.010, train_metric_mse_ts0_dim_0_step=0.835, train_metric_mse_ts0_dim_1_step=1.300, train_metric_mse_ts0_dim_2_step=0.0582, train_metric_mse_ts0_d

Epoch 0: 100%|█| 2/2 [00:08<00:00,  0.23it/s, v_num=jd3o, train_loss_mse_step=1.010, train_metric_mse_ts0_dim_0_step=0.835, train_metric_mse_ts0_dim_1_step=1.300, train_metric_mse_ts0_dim_2_step=0.0582, train_metric_mse_ts0_d
ckpt_path ../outputs/GPT2/240612_175321.9ed302_unifA_unif_C/checkpoints/step=2.ckpt
config path: ../outputs/GPT2/240612_175321.9ed302_unifA_unif_C/checkpoints/step=2.ckpt
Number of validation systems: 3
Number of traces: 7
parent_dir: ../outputs/GPT2/240612_175321.9ed302_unifA_unif_C/checkpoints
parent_parent_dir: ../outputs/GPT2/240612_175321.9ed302_unifA_unif_C
time elapsed: 0.031067848205566406 min
err_lss keys: odict_keys(['Kalman', 'MOP', 'Zero'])
IR length: 1
time elapsed: 0.030733017126719157 min
IR length: 2
time elapsed: 0.034392734368642174 min
IR length: 3
Traceback (most recent call last):
  File "/Users/sultandaniels/Documents/Transformer_Kalman/mop_modifications/streamlined_mop/src/data_train.py", line 104, in <module>
    create_plots(config, run_preds, run_deg_kf_test, excess, num_systems=config.num_val_tasks, shade=shade)
  File "/Users/sultandaniels/Documents/Transformer_Kalman/mop_modifications/streamlined_mop/src/create_plots_with_zero_pred.py", line 649, in create_plots
    handles, err_rat = plot_errs(colors, sys, err_lss_load, irreducible_error_load, ax=ax, shade=shade, normalized=excess)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sultandaniels/Documents/Transformer_Kalman/mop_modifications/streamlined_mop/src/utils/misc.py", line 88, in plot_errs
    handles.extend(ax.plot(avg, label=name if name != "OLS_wentinn" else "OLS_ir_length2_unreg", linewidth=3, marker='o' if name == "MOP" else ".", color = colors[i]))
                                                                                                                                                            ~~~~~~^^^
IndexError: list index out of range
time elapsed: 0.03561458190282186 min
err_lss keys end odict_keys(['Kalman', 'MOP', 'Zero', 'Analytical_Kalman', 'OLS', 'OLS_analytical', 'OLS_wentinn', 'OLS_ir_length1_orig', 'OLS_ir_length2_orig', 'OLS_ir_length3_orig'])
err_lss keys: odict_keys(['Kalman', 'MOP', 'Zero', 'Analytical_Kalman', 'OLS', 'OLS_analytical', 'OLS_wentinn', 'OLS_ir_length1_orig', 'OLS_ir_length2_orig', 'OLS_ir_length3_orig'])
parent_dir: ../outputs/GPT2/240612_175321.9ed302_unifA_unif_C/checkpoints
parent_parent_dir: ../outputs/GPT2/240612_175321.9ed302_unifA_unif_C
parent_dir: ../outputs/GPT2/240612_175321.9ed302_unifA_unif_C/checkpoints
parent_parent_dir: ../outputs/GPT2/240612_175321.9ed302_unifA_unif_C
shape of analytical kalman error: (3, 250)
shape of analytical kalman error: [[0.48086663 0.48086663 0.48086663]
 [0.69540678 0.69540678 0.69540678]
 [0.34538751 0.34538751 0.34538751]]
irreducible_error: [0.48086663468527396, 0.6954067828326131, 0.3453875067858687]
err_lss_load keys: odict_keys(['Kalman', 'MOP', 'Zero', 'Analytical_Kalman', 'OLS', 'OLS_analytical', 'OLS_wentinn', 'OLS_ir_length1_orig', 'OLS_ir_length2_orig', 'OLS_ir_length3_orig'])
[0.48086663 0.69540678 0.34538751]
len(err_lss_load): 10
SYS 0
name Kalman
err_ls.shape (3, 7, 251)
name Kalman
KF (time avergaged mean)/(irreducible):  1.0035733256862343
name MOP
err_ls.shape (3, 7, 251)
name MOP
name Zero
err_ls.shape (3, 7, 251)
name Zero
Zero (time avergaged mean)/(irreducible):  1.7581855851680999
name Analytical_Kalman
err_ls.shape (3, 250)
name OLS
err_ls.shape (3, 7, 251)
name OLS
name OLS_analytical
err_ls.shape (3, 7, 251)
name OLS_analytical
name OLS_wentinn
err_ls.shape (3, 7, 251)
name OLS_wentinn
name OLS_ir_length1_orig
err_ls.shape (3, 7, 251)
name OLS_ir_length1_orig
name OLS_ir_length2_orig
err_ls.shape (3, 7, 251)
name OLS_ir_length2_orig
name OLS_ir_length3_orig
err_ls.shape (3, 7, 251)
name OLS_ir_length3_orig