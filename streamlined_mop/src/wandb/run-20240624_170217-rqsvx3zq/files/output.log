GPU available: True (mps), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/Users/sultandaniels/anaconda3/envs/mop/lib/python3.12/site-packages/pytorch_lightning/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.
/Users/sultandaniels/anaconda3/envs/mop/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:391: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  | Name      | Type      | Params
----------------------------------------
0 | _read_in  | Linear    | 768
1 | _backbone | GPT2Model | 9.1 M
2 | _read_out | Linear    | 645
----------------------------------------
9.1 M     Trainable params
0         Non-trainable params
9.1 M     Total params
36.304    Total estimated model params size (MB)
/Users/sultandaniels/anaconda3/envs/mop/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
batch_size: 28
train_steps: 10
context length: 250
num_tasks: 400
output_dir: ../outputs/GPT2/240624_170213.79223f_gaussA_gauss_C
checkpoint_callback /Users/sultandaniels/Documents/Transformer_Kalman/mop_modifications/streamlined_mop/outputs/GPT2/240624_170213.79223f_gaussA_gauss_C/checkpoints
ckpt_path: ../outputs/GPT2/240624_170213.79223f_gaussA_gauss_C/checkpoints/step=10.ckpt
Checkpoint file ../outputs/GPT2/240624_170213.79223f_gaussA_gauss_C/checkpoints/step=10.ckpt does not exist.
/Users/sultandaniels/anaconda3/envs/mop/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.






Epoch 0: 100%|█| 10/10 [00:13<00:00,  0.77it/s, v_num=x3zq, train_loss_mse_step=0.273, train_metric_

Epoch 0: 100%|█| 10/10 [00:14<00:00,  0.68it/s, v_num=x3zq, train_loss_mse_step=0.273, train_metric_
ckpt_path ../outputs/GPT2/240624_170213.79223f_gaussA_gauss_C/checkpoints/step=10.ckpt
config path: ../outputs/GPT2/240624_170213.79223f_gaussA_gauss_C/checkpoints/step=10.ckpt
Number of validation systems: 3
Number of traces: 2
parent_dir: ../outputs/GPT2/240624_170213.79223f_gaussA_gauss_C/checkpoints
parent_parent_dir: ../outputs/GPT2/240624_170213.79223f_gaussA_gauss_C
time elapsed for MOP Pred: 0.006963002681732178 min
time elapsed for KF Pred: 0.0008871157964070638 min
err_lss keys: odict_keys(['Kalman', 'MOP', 'Zero'])
time elapsed for OLS and OLS Analytical Pred: 0.011229546864827473 min
time elapsed for OLS Wentinn Pred: 0.008386754989624023 min
IR length: 1
time elapsed: 0.008664985497792562 min
IR length: 2
time elapsed: 0.010047014554341633 min
IR length: 3
time elapsed: 0.010021801789601643 min
err_lss keys end odict_keys(['Kalman', 'MOP', 'Zero', 'Analytical_Kalman', 'OLS', 'OLS_analytical', 'OLS_wentinn', 'OLS_ir_length1_orig', 'OLS_ir_length2_orig', 'OLS_ir_length3_orig'])
err_lss keys: odict_keys(['Kalman', 'MOP', 'Zero', 'Analytical_Kalman', 'OLS', 'OLS_analytical', 'OLS_wentinn', 'OLS_ir_length1_orig', 'OLS_ir_length2_orig', 'OLS_ir_length3_orig'])
parent_dir: ../outputs/GPT2/240624_170213.79223f_gaussA_gauss_C/checkpoints
parent_parent_dir: ../outputs/GPT2/240624_170213.79223f_gaussA_gauss_C
parent_dir: ../outputs/GPT2/240624_170213.79223f_gaussA_gauss_C/checkpoints
parent_parent_dir: ../outputs/GPT2/240624_170213.79223f_gaussA_gauss_C
err_lss_load keys: odict_keys(['Kalman', 'MOP', 'Zero', 'Analytical_Kalman', 'OLS', 'OLS_analytical', 'OLS_wentinn', 'OLS_ir_length1_orig', 'OLS_ir_length2_orig', 'OLS_ir_length3_orig'])
[0.28105906 0.41671708 0.34231864]
len(err_lss_load): 10
SYS 0
name Kalman
err_ls.shape (3, 2, 251)
KF (time avergaged mean)/(irreducible):  0.985164403440506
name MOP
err_ls.shape (3, 2, 251)
name Zero
err_ls.shape (3, 2, 251)
Zero (time avergaged mean)/(irreducible):  2.303091184094293
name Analytical_Kalman
err_ls.shape (3, 250)
name OLS
err_ls.shape (3, 2, 251)
name OLS_analytical
err_ls.shape (3, 2, 251)
name OLS_wentinn
err_ls.shape (3, 2, 251)
name OLS_ir_length1_orig
err_ls.shape (3, 2, 251)
name OLS_ir_length2_orig
err_ls.shape (3, 2, 251)
name OLS_ir_length3_orig
err_ls.shape (3, 2, 251)
SYS 1
name Kalman
err_ls.shape (3, 2, 251)
KF (time avergaged mean)/(irreducible):  1.011208288473644
name MOP
err_ls.shape (3, 2, 251)
name Zero
err_ls.shape (3, 2, 251)
Zero (time avergaged mean)/(irreducible):  4.2752543868375446
name Analytical_Kalman
err_ls.shape (3, 250)
name OLS
err_ls.shape (3, 2, 251)
name OLS_analytical
err_ls.shape (3, 2, 251)
name OLS_wentinn
err_ls.shape (3, 2, 251)
name OLS_ir_length1_orig
err_ls.shape (3, 2, 251)
name OLS_ir_length2_orig
err_ls.shape (3, 2, 251)
name OLS_ir_length3_orig
err_ls.shape (3, 2, 251)
SYS 2
name Kalman
err_ls.shape (3, 2, 251)
KF (time avergaged mean)/(irreducible):  1.000440419513978
name MOP
err_ls.shape (3, 2, 251)
name Zero
err_ls.shape (3, 2, 251)
Zero (time avergaged mean)/(irreducible):  6.148759546490232
name Analytical_Kalman
err_ls.shape (3, 250)
name OLS
err_ls.shape (3, 2, 251)
name OLS_analytical
err_ls.shape (3, 2, 251)
name OLS_wentinn
err_ls.shape (3, 2, 251)
name OLS_ir_length1_orig
err_ls.shape (3, 2, 251)
name OLS_ir_length2_orig
err_ls.shape (3, 2, 251)
name OLS_ir_length3_orig
err_ls.shape (3, 2, 251)