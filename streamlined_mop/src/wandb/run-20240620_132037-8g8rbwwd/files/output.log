batch_size: 28
train_steps: 400
context length: 250
num_tasks: 1000
output_dir: ../outputs/GPT2/240620_132027.cdfa3a_upperTriA_gauss_C
checkpoint_callback /Users/sultandaniels/Documents/Transformer_Kalman/mop_modifications/streamlined_mop/outputs/GPT2/240620_132027.cdfa3a_upperTriA_gauss_C/checkpoints
ckpt_path: ../outputs/GPT2/240620_132027.cdfa3a_upperTriA_gauss_C/checkpoints/step=400.ckpt
Traceback (most recent call last):
  File "/Users/sultandaniels/Documents/Transformer_Kalman/mop_modifications/streamlined_mop/src/data_train.py", line 122, in <module>
    train_gpt2(model, config, output_dir) # train the model
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sultandaniels/Documents/Transformer_Kalman/mop_modifications/streamlined_mop/src/train.py", line 51, in train_gpt2
    trainer = pl.Trainer(
              ^^^^^^^^^^^
  File "/Users/sultandaniels/anaconda3/envs/mop/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/sultandaniels/anaconda3/envs/mop/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 401, in __init__
    self._accelerator_connector = _AcceleratorConnector(
                                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/sultandaniels/anaconda3/envs/mop/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 134, in __init__
    self._check_config_and_set_final_flags(
  File "/Users/sultandaniels/anaconda3/envs/mop/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 228, in _check_config_and_set_final_flags
    raise ValueError(
ValueError: You set `strategy=<pytorch_lightning.strategies.ddp.DDPStrategy object at 0x297edb9b0>` but strategies from the DDP family are not supported on the MPS accelerator. Either explicitly set `accelerator='cpu'` or change the strategy.